{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e8c835-8f00-4000-b458-a30a7d6a5cbe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Weaviate](./img/01-cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636dcf47-bc04-4900-923f-cce2a71036c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Weaviate](./img/02-about-weaviate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264e3e3-55bb-4293-9d47-64f30cc34b1e",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Agenda:\n",
    "\n",
    "#### What you will see:\n",
    "\n",
    "- Examples of AI-powered searches\n",
    "- Create and build a vector database\n",
    "- Search with a vector database\n",
    "- Retrieval augmented generation (RAG)\n",
    "- Scalability considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec4eec-eb4d-4397-a26b-f1bd546b52ae",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### You will learn:\n",
    "\n",
    "- About vector, keyword & hybrid searches\n",
    "    - When to use each one\n",
    "- How to perform RAG\n",
    "- How to build a scalable vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cf35f-fe83-4292-91ff-53bed6282f4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Search: An Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7025930-ad27-4e49-a479-e17e5c1a7878",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Try searches using this (pre-populated) toy dataset. \n",
    "\n",
    "```json\n",
    "animal_objs = [\n",
    "    {\"description\": \"brown dog\"},\n",
    "    {\"description\": \"small domestic black cat\"},\n",
    "    {\"description\": \"orange cheetah\"},\n",
    "    {\"description\": \"black bear\"},\n",
    "    {\"description\": \"large white seagull\"},\n",
    "    {\"description\": \"yellow canary\"},\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd1b33-db5d-4982-932b-01d90c5c4e5e",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep script: No need to show\n",
    "\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "from weaviate.classes.query import Filter, MetadataQuery\n",
    "import os\n",
    "\n",
    "# Recommended: save sensitive data as environment variables\n",
    "cohere_key = os.getenv(\"COHERE_APIKEY\")\n",
    "headers = {\n",
    "    \"X-Cohere-Api-Key\": cohere_key,\n",
    "}\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# Work with Weaviate\n",
    "\n",
    "animals = client.collections.delete(\"Animals\")\n",
    "\n",
    "animals = client.collections.create(\n",
    "    name=\"Animals\",\n",
    "    properties=[\n",
    "        Property(name=\"description\", data_type=DataType.TEXT),\n",
    "    ],\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.text2vec_ollama(\n",
    "            name=\"description\",\n",
    "            source_properties=[\"description\"],\n",
    "            api_endpoint=\"http://host.docker.internal:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "            model=\"nomic-embed-text\",  # The model to use, e.g. \"nomic-embed-text\"\n",
    "        )\n",
    "    ],\n",
    "    generative_config=Configure.Generative.ollama(\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "        model=\"gemma2:2b\"\n",
    "    ),\n",
    "    # reranker_config=Configure.Reranker.cohere()\n",
    ")\n",
    "\n",
    "animal_objs = [\n",
    "    {\"description\": \"brown dog\"},\n",
    "    {\"description\": \"small domestic black cat\"},\n",
    "    {\"description\": \"orange cheetah\"},\n",
    "    {\"description\": \"black bear\"},\n",
    "    {\"description\": \"large white seagull\"},\n",
    "    {\"description\": \"yellow canary\"},\n",
    "]\n",
    "\n",
    "animals.data.insert_many(animal_objs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f3336-2a24-4b5b-8f99-485b77d0a714",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Traditional search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aff4d9-5c2a-4bf2-8cc9-d3b111772185",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"cat\"\n",
    "\n",
    "response = animals.query.bm25(query)\n",
    "\n",
    "print(f\"{len(response.objects)} results returned:\")\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be21eea-3eb8-452e-a472-652e7ff9bb38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "But, traditional searches are not very robust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2c0f4-a845-423e-b8a2-5e6404f8c40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"kitty\"  # Try synonyms or even typos\n",
    "\n",
    "response = animals.query.bm25(query)\n",
    "\n",
    "print(f\"{len(response.objects)} results returned:\")\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0118ba5-97a0-4241-a811-be2ddc1dd12c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Vector search\n",
    "\n",
    "But vector search is based on similarity, allowing more forgiving, nuanced search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648b534-4029-4e4b-ae5e-e460b53533ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"cat\"\n",
    "\n",
    "response = animals.query.near_text(query)\n",
    "\n",
    "print(f\"{len(response.objects)} results returned:\")\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29faa18-fa8c-498a-90d4-26f80d40fd33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"cat\"  # Try synonyms or even typos\n",
    "\n",
    "response = animals.query.near_text(query)\n",
    "\n",
    "print(f\"{len(response.objects)} results returned:\")\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedde2c7-b92d-4655-8674-db494c1820b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Vector searches provide forgiving, nuanced, meaning-based similarity search. \n",
    "\n",
    "But - what is a vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86500e-c446-4fbe-916d-fb7af40c1b3b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction to Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4c4b4-ffdf-4158-9511-8bfca1545d54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Vectors](./img/04-vectors-intro-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe73634-dcc2-4a3d-a4c0-4302645c1dc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Vectors](./img/04-vectors-intro-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06fb45-051e-4888-94ca-79bc87351777",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Vectors](./img/04-vectors-intro-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfcdc2-dc5a-41bf-89f6-7b32ef920307",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to Vectors](./img/04-vectors-intro-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e0df1-6a07-4ec9-bfd4-d5e9e8bd3466",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to vectors](./img/04-vectors-intro-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997230d-44a1-4240-8d4e-78f190d5a744",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Why use vector search?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4379e327-97f7-4f81-8773-ccae4c5f9f77",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Better search\n",
    "    - Find contextually relevant info\n",
    "    - Allow synonyms, different languages\n",
    "    - More value from data\n",
    "- Work together with generative AI models\n",
    "    - Overcome hallucinations or lack of specific / prioprietary information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342e374-696f-4515-a761-c5c9e02bd778",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to RAG](./img/06-rag-intro-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022a135-ba46-4139-b9b4-f5f408308e61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to RAG](./img/06-rag-intro-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3957db-7597-4cc1-8412-21c1caeee0d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to RAG](./img/06-rag-intro-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed68ab-da1d-4e61-aa69-4ddc52c9f02d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to RAG](./img/06-rag-intro-04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602cab9b-b77f-4003-89ef-42330d06daa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Example RAG prompts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1179f5-37b6-49ad-b0be-6ae8a37603f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- Summarise the corporate strategy of ACME Co for FY2024-25.\n",
    "- What did the reviewers say about GadgetCo's SmartPhone12?\n",
    "- How do you use Weaviate to perform RAG queries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c26e12-8b9e-4e6b-8bfd-216058190421",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "🤔 How well will these prompts work with *just* keyword searches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d4e72-4d39-48dc-89a5-8ab34162b6f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Introduction to RAG](./img/06-rag-intro-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc8e5f-7e4e-4bfc-91c5-90740c49bc41",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Build a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba26bc3-0958-4051-b31e-9ce27555a8b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Preparation: Get the data\n",
    "\n",
    "We'll use a dataset of movies from TMDB. \n",
    "\n",
    "Pre-processed version: \"./data/movies.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633e880-94bb-4942-9fe1-70ffd2a7afd3",
   "metadata": {},
   "source": [
    "Load (or download) the data, and preview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680be3b-e00f-4c3c-9d42-d9bd8ef1e5a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:50:09.186617Z",
     "start_time": "2023-08-12T20:50:09.042514Z"
    },
    "executionCancelledAt": null,
    "executionTime": 1192,
    "lastExecutedAt": 1692032184432,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import requests\nimport json\n\n# Load the data locally\nwith open(\"jeopardy_1k.json\", \"r\") as f:\n    raw_data = f.read()\n\n# Or download it from GitHub\nresponse = requests.get('https://raw.githubusercontent.com/databyjp/wv_demo_uploader/main/weaviate_datasets/data/jeopardy_1k.json')\nraw_data = response.text\n\n# Parse the JSON and preview it\ndata = json.loads(raw_data)\nprint(type(data), len(data))\nprint(json.dumps(data[0], indent=2))",
    "outputsMetadata": {
     "0": {
      "height": 217,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# movie_df = pd.read_csv(\"./data/movies.csv\")\n",
    "movie_df = pd.read_csv(\"https://raw.githubusercontent.com/weaviate-tutorials/intro-workshop/main/data/movies.csv\")\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27642a1-e738-441c-9008-ce8cb267f28b",
   "metadata": {},
   "source": [
    "## Step 1: Connect to Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a88ba7-6e35-4378-ad30-869537966f01",
   "metadata": {},
   "source": [
    "You can also use a hosted instance on Weaviate Cloud, or install Weaviate anywhere using the open-source distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfea6e",
   "metadata": {},
   "source": [
    "If you are using Cohere, or OpenAI, uncomment and update the relevant lines in the following cell with your actual keys. If yor using Ollama, you do not need to do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\n",
    "    # \"X-Cohere-Api-Key\": \"<your_cohere_apikey>\",  # Replace this with your actual key\n",
    "    # \"X-OpenAI-Api-Key\": \"<your_openai_apikey>\",  # Replace this with your actual key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40b5a3-d645-493b-9c93-e652c1057870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:50:10.463278Z",
     "start_time": "2023-08-12T20:50:10.020181Z"
    },
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 97,
      "type": "stream"
     },
     "1": {
      "height": 257,
      "type": "stream"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# If you have got Weaviate running locally with Kubernetes or Docker:\n",
    "client = weaviate.connect_to_local(\n",
    "    port=80,  # Or 8080 for Docker instances\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "# # If you are waiting for Docker to download, comment out the above, and uncomment this instead:\n",
    "# client = weaviate.connect_to_embedded(\n",
    "#     version=\"1.26.3\",\n",
    "#     headers=headers,\n",
    "#     environment_variables={\n",
    "#         \"ENABLE_API_BASED_MODULES\": \"true\"\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d970d-79a2-4591-a5f3-c6c17406df2a",
   "metadata": {},
   "source": [
    "Retrieve Weaviate instance information to check our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4226e-41fd-4ad7-9416-dcda4a443d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:50:11.726853Z",
     "start_time": "2023-08-12T20:50:11.722015Z"
    },
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1692032185634,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "jprint(client.get_meta())",
    "outputsMetadata": {
     "0": {
      "height": 597,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "client.get_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9706e-e11e-43f8-ae13-3741c5376b25",
   "metadata": {},
   "source": [
    "## Step 2: Add data to Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01b498-455f-4e82-bdb3-df7b95363ca4",
   "metadata": {},
   "source": [
    "### Add collection definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a7ecf-0f04-48a3-b622-dd3673e8302f",
   "metadata": {},
   "source": [
    "The equivalent of a SQL \"table\", is called a \"collection\" in Weaviate, like they are in NoSQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03c144-e2a3-48cc-97db-590fbac55ec0",
   "metadata": {},
   "source": [
    "In case I created a demo collection - let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fdc87-ee1f-43cd-8db7-57b1fda5d697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:50:23.339817Z",
     "start_time": "2023-08-12T20:50:23.303039Z"
    },
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1692032185681,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "if client.schema.exists(\"Question\"):\n    client.schema.delete_class(\"Question\")"
   },
   "outputs": [],
   "source": [
    "client.collections.delete(\"Movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279cefa-ecaf-487c-a090-43a14383e9a1",
   "metadata": {},
   "source": [
    "And create a new collection definition here.\n",
    "We'll set up a collection called \"Movie\" with:\n",
    "- Two \"named vectors\" -> which will save different \"meanings\" of the data,\n",
    "- A \"generative\" module -> which will allow us to use LLMs with our data, and\n",
    "- Properties to save our movie data (which are like SQL columns).\n",
    "    - Just the title, overview, year and popularity for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0db4a-9f72-402c-9c23-49f1500ea995",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:50:24.018171Z",
     "start_time": "2023-08-12T20:50:23.993529Z"
    },
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 77,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, DataType, Property\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Movie\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"overview\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"popularity\",\n",
    "            data_type=DataType.NUMBER,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"year\",\n",
    "            data_type=DataType.INT,\n",
    "        ),\n",
    "    ],\n",
    "    # ========================================\n",
    "    # For those using Ollama:\n",
    "    # ========================================\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.text2vec_ollama(\n",
    "            name=\"title\",\n",
    "            source_properties=[\"title\"],\n",
    "            api_endpoint=\"http://host.docker.internal:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "            model=\"nomic-embed-text\",  # The model to use, e.g. \"snowflake-arctic-embed\"\n",
    "        ),\n",
    "        Configure.NamedVectors.text2vec_ollama(\n",
    "            name=\"all_text\",\n",
    "            source_properties=[\"title\", \"overview\"],\n",
    "            api_endpoint=\"http://host.docker.internal:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "            model=\"nomic-embed-text\",  # The model to use, e.g. \"snowflake-arctic-embed\"\n",
    "        ),\n",
    "    ],\n",
    "    generative_config=Configure.Generative.ollama(\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",\n",
    "        model=\"gemma2:2b\"\n",
    "    ),\n",
    "    # ========================================\n",
    "    # END - Ollama setup\n",
    "    # ========================================\n",
    "    # # ========================================\n",
    "    # # For those using Cohere:\n",
    "    # # ========================================\n",
    "    # vectorizer_config=[\n",
    "    #     Configure.NamedVectors.text2vec_cohere(\n",
    "    #         name=\"title\",\n",
    "    #         source_properties=[\"title\"]\n",
    "    #     ),\n",
    "    #     Configure.NamedVectors.text2vec_cohere(\n",
    "    #         name=\"all_text\",\n",
    "    #         source_properties=[\"title\", \"overview\"]\n",
    "    #     ),\n",
    "    # ],\n",
    "    # generative_config=Configure.Generative.cohere(),\n",
    "    # # ========================================\n",
    "    # # END - Cohere setup\n",
    "    # # ========================================\n",
    "    # # ========================================\n",
    "    # # For those using OpenAI:\n",
    "    # # ========================================\n",
    "    # vectorizer_config=[\n",
    "    #     Configure.NamedVectors.text2vec_openai(\n",
    "    #         name=\"title\",\n",
    "    #         source_properties=[\"title\"]\n",
    "    #     ),\n",
    "    #     Configure.NamedVectors.text2vec_openai(\n",
    "    #         name=\"all_text\",\n",
    "    #         source_properties=[\"title\", \"overview\"]\n",
    "    #     ),\n",
    "    # ],\n",
    "    # generative_config=Configure.Generative.openai(),\n",
    "    # # ========================================\n",
    "    # # END - OpenAI setup\n",
    "    # # ========================================\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fdad45-8916-4c4a-8405-6f28f3eaee40",
   "metadata": {},
   "source": [
    "> Tip: You can get example collection definitions in our documentation:\n",
    "> - https://weaviate.io/developers/weaviate/manage-data/collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17a8e9-da25-4619-9e37-0787383dafe1",
   "metadata": {},
   "source": [
    "Was our collection created successfully? Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed74df-84a7-43a6-bd79-960b0681be7e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1692032185778,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "jprint(client.schema.get(\"Question\"))",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.collections.exists(\"Movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec4752-6428-4db0-b5b3-c36db1b6caaf",
   "metadata": {},
   "source": [
    "### Add data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809f0b6-d816-448a-9619-b8f660b0eef7",
   "metadata": {},
   "source": [
    "We'll add actual objects (SQL rows) to our data. \n",
    "\n",
    "First, let's build objects to add - and take a look at a couple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4453f38-67ac-4de6-9f3d-decc3527149a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1692032185826,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "for o in data[:2]:\n    obj_body = {\n        \"question\": o[\"Question\"],\n        \"answer\": o[\"Answer\"],\n    }\n    print(obj_body)",
    "outputsMetadata": {
     "0": {
      "height": 97,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "data_columns = ['title', 'overview', 'year', 'popularity']\n",
    "\n",
    "df = movie_df[data_columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d65333-ce25-4833-92b7-57ca8113bdb2",
   "metadata": {},
   "source": [
    "> If it all looks fine - let's add objects:\n",
    "> - https://weaviate.io/developers/weaviate/manage-data/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b445597-3655-4606-99e8-8398c50b632d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 6734,
    "lastExecutedAt": 1692032192560,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "with client.batch() as batch:\n    for o in data:\n        obj_body = {\n            \"question\": o[\"Question\"],\n            \"answer\": o[\"Answer\"],\n        }\n        batch.add_data_object(\n            data_object=obj_body,\n            class_name=\"Question\"\n        )",
    "outputsMetadata": {
     "0": {
      "height": 97,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "movies = client.collections.get(\"Movie\")\n",
    "\n",
    "with movies.batch.fixed_size(200) as batch:\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        obj_body = {\n",
    "            c: row[c] for c in data_columns\n",
    "        }\n",
    "        batch.add_object(\n",
    "            properties=obj_body\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d67ac-f92d-4239-b1cb-8c76ea2cf6ca",
   "metadata": {},
   "source": [
    "#### Confirm data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003b6a9-1d0c-4f31-a3a2-945a7a17dfd8",
   "metadata": {},
   "source": [
    "Do we have data? \n",
    "\n",
    "Let's get an object count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cf869-67cd-4b39-b230-23b043217aa3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1692032192610,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "jprint(client.query.aggregate(\"Question\").with_meta_count().do())",
    "outputsMetadata": {
     "0": {
      "height": 277,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "print(len(movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233f9b5-5676-4dc3-bcc8-86df0f86553f",
   "metadata": {},
   "source": [
    "Does the data look right?\n",
    "\n",
    "Let's grab a few objects from Weaviate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e3376-9b3d-4cd6-b27f-e835a9f4eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = movies.query.fetch_objects(limit=3)\n",
    "for o in response.objects:\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c77a3-b0f2-429b-b2fe-78cef9d6ac40",
   "metadata": {},
   "source": [
    "Let's pause for a second - because we've done a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1dbad-dfa7-4f88-a5f5-ea6a0f39e413",
   "metadata": {},
   "source": [
    "#### What did we just do?\n",
    "\n",
    "Here is a conceptual diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436522dc-8cd0-47c4-8286-f839e5a785d4",
   "metadata": {},
   "source": [
    "![img](https://github.com/weaviate-tutorials/intro-workshop/blob/main/images/object_import_process_full.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac15074-c5f6-48e9-9950-35ee265e14d0",
   "metadata": {},
   "source": [
    "## Step 3: Work with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5e47f-c408-4fc4-83f8-4e133d040b3b",
   "metadata": {},
   "source": [
    "Let's try a few more involved queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5740b2-2846-4462-b140-1b1b9c4544ec",
   "metadata": {},
   "source": [
    "### Filtering (similar to WHERE filter in SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c640bf-9f35-4d1e-96e5-455b2fb69fde",
   "metadata": {},
   "source": [
    "Let's find objects that meet a particular condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db451d4b-fcdf-440f-8502-854d970c98d6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1692032192706,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "where_filter = {\n    \"path\": [\"question\"],\n    \"operator\": \"Like\",\n    \"valueText\": \"*history*\"\n}\n\nresponse = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_where(where_filter)\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 477,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "\n",
    "response = movies.query.fetch_objects(\n",
    "    filters=Filter.by_property(\"year\").greater_than(2015),\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd3737-068a-4a88-8386-0148999947ed",
   "metadata": {},
   "source": [
    "But this does not rank the result in any meaningful way. \n",
    "\n",
    "For that, we need a keyword search (as opposed to a keyword *filter*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6553f176-47b5-4c2b-88e2-5c8fea71fe7e",
   "metadata": {},
   "source": [
    "### Keyword search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3d7c7-d376-465e-8a23-841203d54055",
   "metadata": {},
   "source": [
    "Unlike a keyword filter, a keyword search will search for, and rank results based on the frequency of the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d78900-199a-4b8d-8da1-3223c3ada047",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1692032192810,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_bm25(\"history\")\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 477,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "response = movies.query.bm25(\n",
    "    query=\"galaxy\",\n",
    "    limit=5,\n",
    "    return_metadata=MetadataQuery(score=True, last_update_time=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.metadata.score)\n",
    "    print(o.metadata.last_update_time)\n",
    "    print(o.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada69268-32aa-4175-99e8-516e355d5703",
   "metadata": {},
   "source": [
    "### Semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa422c04-ae07-48e4-8202-1ea0615db2a0",
   "metadata": {},
   "source": [
    "A semantic search, on the other hand, searches objects based on similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295bcedc-496d-49a0-b8c1-b3a398d728b8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 159,
    "lastExecutedAt": 1692032192969,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_near_text({\"concepts\": [\"history\"]})\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 477,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = movies.query.near_text(\n",
    "    query=\"galaxy\",\n",
    "    limit=3,\n",
    "    target_vector=\"title\",\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(json.dumps(o.properties, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab8beb0-ab45-4590-a4de-84b68370c026",
   "metadata": {},
   "source": [
    "#### How does this work?\n",
    "\n",
    "- Under the hood, this uses a vector search. It looks for objects which are the most similar to a text input.\n",
    "- We can inspect the similarity along with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a77e4-b27a-4b80-9981-fd975f92e67a",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 142,
    "lastExecutedAt": 1692032193111,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_near_text({\"concepts\": [\"history\"]})\n    .with_additional(\"distance\")\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = movies.query.near_text(\n",
    "    query=\"galaxy\",\n",
    "    limit=3,\n",
    "    target_vector=\"title\",\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.metadata)\n",
    "    print(json.dumps(o.properties, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9e24c-edf7-4f25-ac30-6e291b3ffcad",
   "metadata": {},
   "source": [
    "This is where \"vectors\" come in. \n",
    "\n",
    "Each object in Weaviate includes a vector - like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75ad29-ce85-4bca-beaf-da708b20fb57",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1692032193165,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_additional(\"vector\")\n    .with_limit(1)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = movies.query.near_text(\n",
    "    query=\"galaxy\",\n",
    "    limit=3,\n",
    "    target_vector=\"title\",  # or \"overview\"\n",
    "    include_vector=True,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.metadata.distance)\n",
    "    print(json.dumps(o.properties, indent=2))\n",
    "    print(o.vector[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4097db1-76b0-459c-b5c3-2ee1e0f90abe",
   "metadata": {},
   "source": [
    "These vector representations come from deep learning models to those that power LLMs. They capture meaning, and are called vector \"embeddings\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a055536-649b-4840-8443-c7f15c4f961c",
   "metadata": {},
   "source": [
    "### Generative search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbeb19-3d05-47f4-960f-6f8e9e5dfcc8",
   "metadata": {},
   "source": [
    "A generative search transforms your data at retrieval time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0d7a5-d31b-4b5a-a7d8-96719947a69e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4342,
    "lastExecutedAt": 1692032197507,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_near_text({\"concepts\": [\"history\"]})\n    .with_generate(single_prompt=\"Write a tweet about {question} as an interesting factoid.\")\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "response = movies.generate.near_text(\n",
    "    query=\"galaxy\",\n",
    "    limit=5,\n",
    "    target_vector=\"title\",\n",
    "    single_prompt=\"Write a tweet promoting the movie with TITLE: {title} and OVERVIEW: {overview}.\",\n",
    "    grouped_task=\"What audience demographic might enjoy this group of movies?\"\n",
    ")\n",
    "\n",
    "print(response.generated)\n",
    "for o in response.objects:\n",
    "    print(o.generated)\n",
    "    print(json.dumps(o.properties, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4445d-918d-47c1-a553-688fffbb7164",
   "metadata": {},
   "source": [
    "You can see here ⬆️ that each object has been transformed into a tweet by the LLM based on our prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd87179-0c9b-42f8-85f0-8d790dafa4ad",
   "metadata": {},
   "source": [
    "You can ask LLMs to perform all sorts of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03472eb3-b993-4c6b-80c5-058d52ca0fbb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2226,
    "lastExecutedAt": 1692032199733,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = (\n    client.query\n    .get(\"Question\", [\"question\", \"answer\"])\n    .with_near_text({\"concepts\": [\"history\"]})\n    .with_generate(single_prompt=\"Translate {question} into French.\")\n    .with_limit(3)\n    .do()\n)\n\njprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "response = movies.generate.near_text(\n",
    "    query=\"galaxy\",\n",
    "    target_vector=\"title\",\n",
    "    limit=3,\n",
    "    single_prompt=\"Summarise the following movie overview into a short French sentence: {overview}.\"\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.generated)\n",
    "    print(json.dumps(o.properties, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03f4fb-8a08-41a7-a7d1-dc1ebc14fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
